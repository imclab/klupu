#!/usr/bin/env python3
# -*- coding: utf-8 -*-
#
# klupu - scrape meeting minutes of governing bodies of city of Jyväskylä
# Copyright (C) 2012 Tuomas Jorma Juhani Räsänen <tuomasjjrasanen@tjjr.fi>
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

import datetime
import glob
import itertools
import json
import os.path
import re
import sys
import warnings

def showwarning(message, category, filename, lineno, *args):
    try:
        file = args[0]
    except IndexError:
        file = sys.stderr
    print("klupu: %s:" % category.__name__, message, file=file)

warnings.showwarning = showwarning

from bs4 import BeautifulSoup

RE_DATE = re.compile(r"^\D*(\d\d?)\.(\d\d?)\.(\d{4})\D+")
RE_TIME = re.compile(r"(\d\d?)\D?(\d\d)\D+(\d\d?)\D?(\d\d)")
RE_PERSON = re.compile(r"^([A-ZÖÄÅ][a-zöäå]*(?:-[A-ZÖÄÅ][a-zöäå]*)*(?: [A-ZÖÄÅ][a-zöäå]*(?:-[A-ZÖÄÅ][a-zöäå]*)*)+)")
RE_PRESENCE_MARK = re.compile(r"^([–-].*)?[xX][\xa0 ]+")
RE_DNRO = re.compile(r"^Dnro[\xa0 :]+(\d+[ ]?/\d+)$")
RE_TITLE = re.compile(r"^(\d+)[\xa0 ]+(.*)$")
RE_DECISION = re.compile(r"^Päätös[\xa0 ]+(.*)$")
FILENAME_INFO = "htmtxt0.htm"

def iter_issue_filepaths(minutes_dirpath):
    pathname = os.path.join(minutes_dirpath, "htmtxt*.htm")
    for issue_filepath in glob.iglob(pathname):
        if os.path.basename(issue_filepath) != FILENAME_INFO:
            yield issue_filepath

def cleanws(text):
    text = re.sub(r"[\r\n]", " ", text)
    text = re.sub(r"\xad+", "", text)
    text = re.sub(r"\xa0+", "\xa0", text)
    text = re.sub(r"[ ]+", " ", text)
    return text

def thresh_meetinginfo(soup):
    markerspan = soup(text=re.compile("KOKOUSTIEDOT"))[0].parent
    ps = markerspan.parent.parent.parent("td")[1]("p")

    texts = [cleanws(p.text) for p in ps]
    assert(texts[0] == "\xa0")
    starttimes = []
    endtimes = []
    place = None
    for text in texts[1:-1]:
        try:
            s, e = thresh_datetime(text)
        except AttributeError as err:
            if str(err) != "'NoneType' object has no attribute 'groups'":
                raise err
            place = text
        starttimes.extend(s)
        endtimes.extend(e)
    place = place or texts[-1]

    return place, starttimes, endtimes

def thresh_datetime(text):
    # TODO: handle constant timezone + variable DST
    date_match = RE_DATE.match(text)
    day, month, year = [int(v) for v in date_match.groups()]
    starttimes = []
    endtimes = []
    for times in RE_TIME.findall(text, date_match.end()):
        starthour, startminutes, endhour, endminutes = [int(v) for v in times]
        endhour %= 24 # Someone uses stupid format to denote that this
                      # is part of the yesterday..
        starttime = datetime.datetime(year, month, day, starthour, startminutes)
        endtime = datetime.datetime(year, month, day, endhour, endminutes)
        if starttime > endtime:
            # If the end-time is after midnight, add one day to the
            # date part.
            endtime += datetime.timedelta(1)
        starttimes.append(starttime)
        endtimes.append(endtime)
    assert(0 < len(starttimes) == len(endtimes))
    return starttimes, endtimes

def is_almost_empty(line):
    return not line or re.match(r"[\xa0 ]+", line)

def thresh_persons(td):
    persons = []
    for line in [cleanws(p.text) for p in td("p")]:
        if is_almost_empty(line):
            continue

        presence_mark_match = RE_PRESENCE_MARK.match(line)
        if not presence_mark_match:
            warnings.warn("skipping participant info")
            continue

        person_match = RE_PERSON.match(line[presence_mark_match.end():])
        persons.append(person_match.group(1))

    return persons

def thresh_decisionmakers(soup):
    markerspan = soup(text=re.compile("Päätöksentekijä"))[0].parent
    td = markerspan.parent.parent.parent("td")[1]
    return thresh_persons(td)

def thresh_others(soup):
    markerspan = soup(text=re.compile("Muut läsnäolijat"))[0].parent
    td = markerspan.parent.parent.parent("td")[1]
    return thresh_persons(td)

def thresh_issue_title(soup):
    numbered_title = cleanws(soup.html.body("p", {"class": "Asiaotsikko"})[0].text)
    title_match = RE_TITLE.match(numbered_title)
    if title_match:
        number, title = title_match.groups()
        number = int(number)
    else:
        warnings.warn("numbered title not found")
        number = None
        title = None

    return number, title

def thresh_dnro(soup):
    ps = soup.html.body("p")
    dnros = []
    for p in ps:
        dnro_match = RE_DNRO.match(cleanws(p.text))
        if dnro_match:
            dnros.append(dnro_match.group(1))

    try:
        dnro = dnros[0]
    except IndexError:
        # Some of the issues in each meeting are "standard" issues,
        # e.g. opening of the meeting, determination of quorum, which
        # do not have Dnro.
        dnro = None
        warnings.warn("dnro not found")

    if len(dnros) > 1:
        warnings.warn("multiple dnros found")

    if dnro == "0/00":
        dnro = None

    return dnro

def thresh_decision(soup):
    decision = None
    decision_ps = soup.html.body("p")
    for decision_p in decision_ps:
        decision_match = RE_DECISION.match(cleanws(decision_p.text))
        if decision_match:
            decision = decision_match.group(1)
    return decision

def thresh_issue(soup):
    number, title = thresh_issue_title(soup)
    dnro = thresh_dnro(soup)
    decision = thresh_decision(soup)
    return {
        "number": number,
        "dnro": dnro,
        "title": title,
        "decision": decision,
        }

def get_soup(filepath, encoding):
    with open(filepath, encoding=encoding, errors="replace") as f:
        return BeautifulSoup(f, from_encoding=encoding)

def thresh(minutes_dirpath):
    minutes_dirpath = os.path.normpath(minutes_dirpath)

    issues = []
    for issue_filepath in iter_issue_filepaths(minutes_dirpath):
        issues.append(thresh_issue(get_soup(issue_filepath, "windows-1252")))

    index_filepath = os.path.join(minutes_dirpath, "index.htm")
    index_soup = get_soup(index_filepath, "iso-8859-15")

    selfurl = index_soup.html.body("a", target="_self")[0]["href"]
    body = os.path.splitext(os.path.basename(selfurl))[0]

    info_filepath = os.path.join(minutes_dirpath, FILENAME_INFO)
    info_soup = get_soup(info_filepath, "windows-1252")

    place, starttimes, endtimes = thresh_meetinginfo(info_soup)
    decisionmakers = thresh_decisionmakers(info_soup)
    others = thresh_others(info_soup)

    return {
        "body": body,
        "place": place,
        "start-times": starttimes,
        "end-times": endtimes,
        "decision-makers": decisionmakers,
        "others": others,
        "issues": issues,
        }

def json_dump(grains):
    body = grains["body"]
    starttime = grains["start-times"][0].strftime("%Y-%m-%d-%H-%M")

    # Jason does not know how to serialize datetimes, let's do it for
    # him this time.
    grains["start-times"] = [d.isoformat() for d in grains["start-times"]]
    grains["end-times"] = [d.isoformat() for d in grains["end-times"]]

    with open("%s-%s.json" % (body, starttime), "w") as json_file:
        json.dump(grains, json_file, ensure_ascii=False, indent=1)

def _main():
    for minutes_dirpath in sys.argv[1:]:
        grains = thresh(minutes_dirpath)
        json_dump(grains)

if __name__ == "__main__":
    _main()
